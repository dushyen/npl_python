{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# imported necessary libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('database.sqlite') \n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 limit 1000\n",
    "\"\"\", con) \n",
    "\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.kaggle.com/premvardhan/amazon-fine-food-reviews-analysis-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      0  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      0  1219017600   \n",
       "3                     3                       3      1  1307923200   \n",
       "4                     0                       0      0  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape #looking at the number of attributes and size of the data\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 10)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = sorted_data.drop_duplicates(subset = {\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final = final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    841\n",
       "1    157\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "i=0;\n",
    "for sent in final['Text'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "    i += 1;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ours', 'yourself', 'from', 'own', 'and', 'don', 'yourselves', 'under', 'should', 'than', 't', 'what', 'did', \"should've\", \"needn't\", \"shouldn't\", 'for', 'some', 'so', 'there', 'haven', 'doing', 'd', 'she', 'herself', 'he', 'ma', 'ain', \"won't\", 'how', 'does', 'ourselves', 've', 'above', 'isn', 'do', 'am', 'off', 'then', 'any', \"that'll\", 'has', \"wouldn't\", 'him', 'but', \"you'd\", 'the', 'very', 'you', 'all', 'not', 'couldn', 'in', \"mustn't\", \"she's\", 'over', \"it's\", 'between', 'hers', \"hasn't\", 'be', 'o', 're', 'been', 'had', 'why', 'shan', 'before', 'being', \"don't\", 'only', 'hasn', 'your', 'on', 'mightn', 'who', 'here', 'into', 'further', 'same', 'at', 'to', 'itself', 'are', 'theirs', 'needn', 'mustn', 'weren', 'doesn', 'or', 'was', 'were', 'can', 'each', 'yours', 'm', 's', 'about', \"you'll\", 'aren', 'didn', 'y', 'because', 'shouldn', 'now', 'll', \"doesn't\", 'a', 'below', 'other', \"wasn't\", 'her', \"didn't\", 'most', 'that', 'i', 'its', 'more', \"aren't\", 'against', 'we', 'when', 'me', 'up', 'nor', 'his', 'where', 'these', 'out', 'hadn', 'again', 'no', 'it', \"you're\", 'by', 'whom', 'while', 'myself', 'wasn', \"haven't\", 'just', 'will', \"couldn't\", 'my', \"hadn't\", 'an', \"weren't\", 'those', 'is', \"you've\", 'such', 'them', 'of', 'after', 'himself', 'having', 'their', 'as', 'if', 'too', 'which', \"mightn't\", 'through', 'this', 'until', 'won', 'during', 'with', 'few', 'down', 'both', 'have', \"shan't\", 'wouldn', 'they', 'once', 'themselves', \"isn't\", 'our'}\n",
      "************************************\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "print(stop)\n",
    "print('************************************')\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "# this code takes a while to run as it needs to run on 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.head(3) #below the processed review can be seen in the CleanedText Column \n",
    "\n",
    "\n",
    "# store final table into an SQlLite table for future.\n",
    "conn = sqlite3.connect('final.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"final.sqlite\")\n",
    "cleaned_data = pd.read_sql_query(\"select * from Reviews\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>B0001PB9FE</td>\n",
       "      <td>A3HDKO7OW0QNK4</td>\n",
       "      <td>Canadian Fan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1107820800</td>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "      <td>b'dont know cactus tequila uniqu combin ingred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>253</td>\n",
       "      <td>B0002567IW</td>\n",
       "      <td>A1SSKFPX72MSMR</td>\n",
       "      <td>Janna M. Sicard \"missjanna\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1344556800</td>\n",
       "      <td>Sad outcome</td>\n",
       "      <td>Five minutes in, one tentacle was bitten off, ...</td>\n",
       "      <td>b'five minut one tentacl bitten ball insid cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171</td>\n",
       "      <td>188</td>\n",
       "      <td>B00029XIZI</td>\n",
       "      <td>A2S72TUJDQUBMH</td>\n",
       "      <td>Nadia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1236124800</td>\n",
       "      <td>Miracle</td>\n",
       "      <td>My Scotties were full of hot spots and when I ...</td>\n",
       "      <td>b'scotti full hot spot use within week hot spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932</td>\n",
       "      <td>1011</td>\n",
       "      <td>B0002MKFEM</td>\n",
       "      <td>A3QLX72AO0DD5Z</td>\n",
       "      <td>Carlito Picache</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1226361600</td>\n",
       "      <td>Way too salty</td>\n",
       "      <td>I tried this and I found it too salty.&lt;br /&gt;Pl...</td>\n",
       "      <td>b'tri found salti plus ate fish sauc fish real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>893</td>\n",
       "      <td>969</td>\n",
       "      <td>B0002XIB2Y</td>\n",
       "      <td>A3NV17B17PFB7G</td>\n",
       "      <td>Susan</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1228176000</td>\n",
       "      <td>WONDERFUL gravy!</td>\n",
       "      <td>This gravy mix is excellent ... except, don't ...</td>\n",
       "      <td>b'gravi mix excel except dont use water call u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    Id   ProductId          UserId                  ProfileName  \\\n",
       "0     10    11  B0001PB9FE  A3HDKO7OW0QNK4                 Canadian Fan   \n",
       "1    232   253  B0002567IW  A1SSKFPX72MSMR  Janna M. Sicard \"missjanna\"   \n",
       "2    171   188  B00029XIZI  A2S72TUJDQUBMH                        Nadia   \n",
       "3    932  1011  B0002MKFEM  A3QLX72AO0DD5Z              Carlito Picache   \n",
       "4    893   969  B0002XIB2Y  A3NV17B17PFB7G                        Susan   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      0  1107820800   \n",
       "1                     0                       0      1  1344556800   \n",
       "2                     0                       0      0  1236124800   \n",
       "3                     1                       2      0  1226361600   \n",
       "4                     3                       3      0  1228176000   \n",
       "\n",
       "                           Summary  \\\n",
       "0  The Best Hot Sauce in the World   \n",
       "1                      Sad outcome   \n",
       "2                          Miracle   \n",
       "3                    Way too salty   \n",
       "4                 WONDERFUL gravy!   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I don't know if it's the cactus or the tequila...   \n",
       "1  Five minutes in, one tentacle was bitten off, ...   \n",
       "2  My Scotties were full of hot spots and when I ...   \n",
       "3  I tried this and I found it too salty.<br />Pl...   \n",
       "4  This gravy mix is excellent ... except, don't ...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'dont know cactus tequila uniqu combin ingred...  \n",
       "1  b'five minut one tentacl bitten ball insid cra...  \n",
       "2  b'scotti full hot spot use within week hot spo...  \n",
       "3  b'tri found salti plus ate fish sauc fish real...  \n",
       "4  b'gravi mix excel except dont use water call u...  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    841\n",
       "1    157\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[\"Score\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 12)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To randomly sample 100k points from both class\n",
    "\n",
    "data_pos = cleaned_data[cleaned_data[\"Score\"] == 0].sample(n = 100)\n",
    "data_neg = cleaned_data[cleaned_data[\"Score\"] == 1].sample(n = 100)\n",
    "final_100k = pd.concat([data_pos, data_neg])\n",
    "final_100k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>672</td>\n",
       "      <td>724</td>\n",
       "      <td>B000G6MBX2</td>\n",
       "      <td>A1ABDQ02BCIGYQ</td>\n",
       "      <td>HM</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-03-14</td>\n",
       "      <td>Not, my favorite chip</td>\n",
       "      <td>I did not like these potatoe chips. It's hot, ...</td>\n",
       "      <td>b'like potato chip hot sweet overwhelm tast ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>664</td>\n",
       "      <td>715</td>\n",
       "      <td>B000G6MBX2</td>\n",
       "      <td>A14B8M117EUBLK</td>\n",
       "      <td>Shelly Kenyon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-06-01</td>\n",
       "      <td>Best tortilla chips ever!!!</td>\n",
       "      <td>We like these chips for salsa and quacomole be...</td>\n",
       "      <td>b'like chip salsa quacomol better cip market e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>460</td>\n",
       "      <td>498</td>\n",
       "      <td>B000G6RYNE</td>\n",
       "      <td>AJQD2WWJYOYFQ</td>\n",
       "      <td>bubbles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-08-09</td>\n",
       "      <td>Tangy, spicy, and sweet- oh my!</td>\n",
       "      <td>Kettle Chips Spicy Thai potato chips have the ...</td>\n",
       "      <td>b'kettl chip spici thai potato chip perfect am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>734</td>\n",
       "      <td>791</td>\n",
       "      <td>B000UZMJZO</td>\n",
       "      <td>A2V71J7J3DTB5B</td>\n",
       "      <td>Vehred</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-27</td>\n",
       "      <td>If I could give a rating under one-star...</td>\n",
       "      <td>This tea carries the flavor one would expect f...</td>\n",
       "      <td>b'tea carri flavor one would expect terribl in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>366</td>\n",
       "      <td>399</td>\n",
       "      <td>B001ELL6O8</td>\n",
       "      <td>ALSAOZ1V546VT</td>\n",
       "      <td>A Research It Maven \"Just the facts please\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-01-13</td>\n",
       "      <td>Arrowhead Mills whole grain buttermilk Pancake...</td>\n",
       "      <td>HEY! These are GREAT Waffles and Pancakes! We ...</td>\n",
       "      <td>b'hey great waffl pancak add mix tho recipi ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   Id   ProductId          UserId  \\\n",
       "86     672  724  B000G6MBX2  A1ABDQ02BCIGYQ   \n",
       "117    664  715  B000G6MBX2  A14B8M117EUBLK   \n",
       "240    460  498  B000G6RYNE   AJQD2WWJYOYFQ   \n",
       "415    734  791  B000UZMJZO  A2V71J7J3DTB5B   \n",
       "515    366  399  B001ELL6O8   ALSAOZ1V546VT   \n",
       "\n",
       "                                     ProfileName  HelpfulnessNumerator  \\\n",
       "86                                            HM                     3   \n",
       "117                                Shelly Kenyon                     0   \n",
       "240                                      bubbles                     0   \n",
       "415                                       Vehred                     2   \n",
       "515  A Research It Maven \"Just the facts please\"                     1   \n",
       "\n",
       "     HelpfulnessDenominator  Score       Time  \\\n",
       "86                        7      1 2007-03-14   \n",
       "117                       0      0 2007-06-01   \n",
       "240                       0      0 2007-08-09   \n",
       "415                       3      1 2007-11-27   \n",
       "515                       1      0 2008-01-13   \n",
       "\n",
       "                                               Summary  \\\n",
       "86                               Not, my favorite chip   \n",
       "117                        Best tortilla chips ever!!!   \n",
       "240                    Tangy, spicy, and sweet- oh my!   \n",
       "415         If I could give a rating under one-star...   \n",
       "515  Arrowhead Mills whole grain buttermilk Pancake...   \n",
       "\n",
       "                                                  Text  \\\n",
       "86   I did not like these potatoe chips. It's hot, ...   \n",
       "117  We like these chips for salsa and quacomole be...   \n",
       "240  Kettle Chips Spicy Thai potato chips have the ...   \n",
       "415  This tea carries the flavor one would expect f...   \n",
       "515  HEY! These are GREAT Waffles and Pancakes! We ...   \n",
       "\n",
       "                                           CleanedText  \n",
       "86   b'like potato chip hot sweet overwhelm tast ga...  \n",
       "117  b'like chip salsa quacomol better cip market e...  \n",
       "240  b'kettl chip spici thai potato chip perfect am...  \n",
       "415  b'tea carri flavor one would expect terribl in...  \n",
       "515  b'hey great waffl pancak add mix tho recipi ba...  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_100k[\"Time\"] = pd.to_datetime(final_100k[\"Time\"], unit = \"s\")\n",
    "final_100k = final_100k.sort_values(by = \"Time\")\n",
    "final_100k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (100,)\n"
     ]
    }
   ],
   "source": [
    "# 100k data which will use to train model after vectorization\n",
    "X = final_100k[\"CleanedText\"]\n",
    "print(\"shape of X:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y: (100,)\n"
     ]
    }
   ],
   "source": [
    "# class label\n",
    "y = final_100k[\"Score\"]\n",
    "print(\"shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532    0\n",
       "304    0\n",
       "517    1\n",
       "239    0\n",
       "341    0\n",
       "84     0\n",
       "528    1\n",
       "349    0\n",
       "105    0\n",
       "192    1\n",
       "198    1\n",
       "322    0\n",
       "166    1\n",
       "163    1\n",
       "275    0\n",
       "81     0\n",
       "674    0\n",
       "161    1\n",
       "456    1\n",
       "511    0\n",
       "281    0\n",
       "221    0\n",
       "417    1\n",
       "627    1\n",
       "164    1\n",
       "366    1\n",
       "570    1\n",
       "45     1\n",
       "481    1\n",
       "549    1\n",
       "      ..\n",
       "504    1\n",
       "538    0\n",
       "595    0\n",
       "302    1\n",
       "606    0\n",
       "67     1\n",
       "465    0\n",
       "510    0\n",
       "402    1\n",
       "707    0\n",
       "883    1\n",
       "492    1\n",
       "739    1\n",
       "889    0\n",
       "283    0\n",
       "183    1\n",
       "859    0\n",
       "667    1\n",
       "892    0\n",
       "245    0\n",
       "787    0\n",
       "142    0\n",
       "736    1\n",
       "564    1\n",
       "168    1\n",
       "691    1\n",
       "620    0\n",
       "963    1\n",
       "472    0\n",
       "181    1\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this program on your local python \n",
    "# interpreter, provided you have installed \n",
    "# the required libraries. \n",
    "\n",
    "# Importing the required packages \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "#from sklearn.cross_validation import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "#from sklearn import cross_validation\n",
    "\n",
    "# Function importing Dataset \n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=False)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-5661572ee05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#X_train = bow.fit_transform(X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1032\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    326\u001b[0m                                                tokenize)\n\u001b[1;32m    327\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 328\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "bow = CountVectorizer()\n",
    "#X_train = bow.fit_transform(X_train)\n",
    "y_train = bow.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322    0\n",
       "510    0\n",
       "966    0\n",
       "481    1\n",
       "971    1\n",
       "84     0\n",
       "620    0\n",
       "691    1\n",
       "365    1\n",
       "674    0\n",
       "707    0\n",
       "165    1\n",
       "349    0\n",
       "592    1\n",
       "45     1\n",
       "511    0\n",
       "921    1\n",
       "366    1\n",
       "736    1\n",
       "163    1\n",
       "164    1\n",
       "239    0\n",
       "161    1\n",
       "66     1\n",
       "105    0\n",
       "932    1\n",
       "528    1\n",
       "168    1\n",
       "457    1\n",
       "873    1\n",
       "      ..\n",
       "981    0\n",
       "538    0\n",
       "892    0\n",
       "402    1\n",
       "521    0\n",
       "667    1\n",
       "874    1\n",
       "594    1\n",
       "984    1\n",
       "245    0\n",
       "564    1\n",
       "980    0\n",
       "458    1\n",
       "549    1\n",
       "304    0\n",
       "739    1\n",
       "221    0\n",
       "517    1\n",
       "627    1\n",
       "854    1\n",
       "928    0\n",
       "911    0\n",
       "842    1\n",
       "881    1\n",
       "281    0\n",
       "787    0\n",
       "901    0\n",
       "275    0\n",
       "986    1\n",
       "492    1\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'secret high fructos corn syrup detriment health unfortun also secret replac form sugar disturb larg number manufactur food even wors high fructos corn syrup made genet modifi corn sinc late hfcs replac regular tabl sugar honey similar sweeten practic everyth prolong consumpt hfcs topic much debat learn caus damag bodi high fructos corn syrup danger signific risk weight gain obes increas risk develop diabet hypertens elev bad cholesterol level liver damag mercuri exposur hfcs kellogg manufactur know slowli get rid sweetner look cover post rain bran advertis contain high fructos corn syrup applaud high fructos corn syrup made genet modifi corn monsanto use system pesticid seed caus coloni collaps disord bee bee keeper avoid product hfcs save famili bee watch vanish bee food matter food inc sold amazon excel movi chang health dramat way think eat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-35c9c14f2a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Calling main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-229-35c9c14f2a3e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Building Phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mclf_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_using_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mclf_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarin_using_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-229-35c9c14f2a3e>\u001b[0m in \u001b[0;36mtrain_using_gini\u001b[0;34m(X_train, X_test, y_train)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Performing training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mclf_gini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclf_gini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/root/anaconda2/envs/py34/lib/python3.4/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: b'secret high fructos corn syrup detriment health unfortun also secret replac form sugar disturb larg number manufactur food even wors high fructos corn syrup made genet modifi corn sinc late hfcs replac regular tabl sugar honey similar sweeten practic everyth prolong consumpt hfcs topic much debat learn caus damag bodi high fructos corn syrup danger signific risk weight gain obes increas risk develop diabet hypertens elev bad cholesterol level liver damag mercuri exposur hfcs kellogg manufactur know slowli get rid sweetner look cover post rain bran advertis contain high fructos corn syrup applaud high fructos corn syrup made genet modifi corn monsanto use system pesticid seed caus coloni collaps disord bee bee keeper avoid product hfcs save famili bee watch vanish bee food matter food inc sold amazon excel movi chang health dramat way think eat'"
     ]
    }
   ],
   "source": [
    "def train_using_gini(X_train, X_test, y_train): \n",
    "\n",
    "\t# Creating the classifier object \n",
    "\tclf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "\t\t\trandom_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "\n",
    "\t# Performing training \n",
    "\tclf_gini.fit(X_train, y_train) \n",
    "\treturn clf_gini \n",
    "\t\n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "\n",
    "\t# Decision tree with entropy \n",
    "\tclf_entropy = DecisionTreeClassifier( \n",
    "\t\t\tcriterion = \"entropy\", random_state = 100, \n",
    "\t\t\tmax_depth = 3, min_samples_leaf = 5) \n",
    "\n",
    "\t# Performing training \n",
    "\tclf_entropy.fit(X_train, y_train) \n",
    "\treturn clf_entropy \n",
    "\n",
    "\n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "\n",
    "\t# Predicton on test with giniIndex \n",
    "\ty_pred = clf_object.predict(X_test) \n",
    "\tprint(\"Predicted values:\") \n",
    "\tprint(y_pred) \n",
    "\treturn y_pred \n",
    "\t\n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "\t\n",
    "\tprint(\"Confusion Matrix: \", \n",
    "\t\tconfusion_matrix(y_test, y_pred)) \n",
    "\t\n",
    "\tprint (\"Accuracy : \", \n",
    "\taccuracy_score(y_test,y_pred)*100) \n",
    "\t\n",
    "\tprint(\"Report : \", \n",
    "\tclassification_report(y_test, y_pred)) \n",
    "\n",
    "# Driver code \n",
    "def main(): \n",
    "\t\n",
    "\t# Building Phase \n",
    "\tclf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "\tclf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "\t\n",
    "\t# Operational Phase \n",
    "\tprint(\"Results Using Gini Index:\") \n",
    "\t\n",
    "\t# Prediction using gini \n",
    "\ty_pred_gini = prediction(X_test, clf_gini) \n",
    "\tcal_accuracy(y_test, y_pred_gini) \n",
    "\t\n",
    "\tprint(\"Results Using Entropy:\") \n",
    "\t# Prediction using entropy \n",
    "\ty_pred_entropy = prediction(X_test, clf_entropy) \n",
    "\tcal_accuracy(y_test, y_pred_entropy) \n",
    "\t\n",
    "\t\n",
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "\tmain() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
